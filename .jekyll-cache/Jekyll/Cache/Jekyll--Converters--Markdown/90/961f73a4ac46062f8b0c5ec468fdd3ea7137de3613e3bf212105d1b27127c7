I".	<p><br />
<br /></p>
<h3 id="introduction">Introduction</h3>

<hr />

<p>이전 포스트에서 VGG 모델이 잠깐 언급되었는데 VGG 모델의 의의는 기존에 존재하던 모델에 비해 깊은 feature extraction 층을 가지고 있으면서도 정확도가 높다는 점이었다. 여담으로 VGG-16d에서의 16은 레이어의 개수를 뜻한다.</p>

<p>다른 차이점은 이전에 존재하던 정확도 높은 모델들은 큰 필터의 \(7\times7\) 등의 필터를 사용하였으나 VGG 모델은 \(3\times3\)의 작은 필터만을 사용하였음에도 기존보다 더 높은 정확도를 보여준다.</p>

<p>예시로 \(10\times10\) 의 이미지(흰색 바탕)에 \(7\times7\) 필터를 사용하여 convolution 연산을 하게되면 output의 feature map 1 pixel(\(4\times4\) 사각형의의 노란색 사각형 한 개)은 본래의 이미지의 \(7\times7\) 만큼의 정보를 담는다.(그리고 이를 <strong>receptive field</strong>라고 한다).</p>

<p><img src="https://user-images.githubusercontent.com/52132160/101345628-aeac2a80-38ca-11eb-8ecc-b51b36640af2.png" alt="image" /></p>

<p>하지만 \(3\times3\) convolution 연산을 3번 수행하게 되면 \(7\times7\) 연산을 한번 수행한 것과 같은 receptive field를 가진다.(아래 그림의 빨간색 사각형 부분을 잘 살펴보면 된다.)
<img src="https://user-images.githubusercontent.com/52132160/101346747-5b3adc00-38cc-11eb-9c1c-5f742e3f2ebb.png" alt="image" /></p>

<p>출처: <a href="https://medium.com/@msmapark2/vgg16-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-very-deep-convolutional-networks-for-large-scale-image-recognition-6f748235242a">VGG16 논문 리뷰 — Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p>

<p>이러한 연산의 장점은 첫째, convolution 층을 많이 쌓으면서 사용하게 되는 ReLU 함수로 인해 비선형성이 증가하며 사진의 특징을 더 잘 구분하도록 하는 장점이 있다. 두 번째는 파라미터 수의 감소에 있다. 필터의 크기 = 파라미터의 크기이니 대충 계산해봐도 파라미터 수가 거의 2배 가까이 감소하였음을 알 수 있다.</p>

<p><br />
<br /></p>

<h3 id="vgg의-문제점-그리고-resnet">VGG의 문제점, 그리고 ResNet</h3>

<hr />

<p>###</p>

<hr />

<p>###</p>

<hr />

:ET