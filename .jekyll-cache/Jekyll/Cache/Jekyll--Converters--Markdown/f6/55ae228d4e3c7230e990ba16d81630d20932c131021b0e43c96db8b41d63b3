I"1	<hr />

<p>Introduction</p>

<hr />

<p>Transfer Learning, 한국말로 <strong>전이학습</strong> 이라 불리는 방법은 이미지 처리에서 높은 정확도를 보여주는 학습 방법이다.
cifar-10에서 직접 만든 모델로 정확도를 측정하였을 때, 80%에 미치지 못하는 정확도를 보여주었고 여러 방면으로 시도 해보아도 쉽지 않은 과정이었다.
그러나 전이학습을 통해 90% 대의 정확도를 낼 수 있다는 얘기를 들었고 궁금증을 이기지 못하여 직접 찾아보게 되었다.</p>

<hr />

<h3 id="transfer-learning">Transfer Learning</h3>

<p>전이학습은 단기간 내에 높은 정확도를 낼 수 있다고 한다. 전이학습을 통해 나처럼 직접 모델을 한 층씩 만들지 않고 이미 학습된 weight와 bias를 통해 다양한 분류 문제에 적용할 수 있다. 이미지 처리에서의 전이학습은 pre-trained model 즉 이미 학습된 모델을 이용하는 것이라고 한다. pre-trained model은 대량의 데이터를 통해 이미 학습이 되어 있는 모델이다. 예를 들면 VGG 모델은 애초에 classification label이 1000개일 정도로 엄청난 데이터 수를 자랑한고 그렇게 많은 데이터를 학습시킨다는 건 너무나도 많은 시간이 필요하기에 공개된 모델을 import해서 사용한다.</p>

<hr />

<h3 id="transfer-learning의-방법들">Transfer Learning의 방법들</h3>

<ol>
  <li>
    <p>전체 모델의 구조만 가져와 새롭게 학습하는 방식</p>
  </li>
  <li>
    <p>모델의 feature extraction 파트는 pre-train된 상태로 가져오되 classifier 단을 목적에 맞게 새롭게 세팅</p>
  </li>
  <li>
    <p>feature extraction의 일부는 freeze하고 나머지를 모두 새롭게 학습, classifier 단 역시 목적에 맞게 세팅</p>
  </li>
</ol>

<p>결국 위 세 가지 방식 모두 classifier 단을 본인의 목적에 맞게 세팅을 한다는 공통점이 있고</p>

<p>대체로 2번 방식을 사용한다고 한다. 이유는 다양한 label에 맞춰 학습된 방식이 새롭게 학습을 하는 방식보다 분류를 잘하기 때문이라고 한다. ( + 혹은 본인의 데이터를 통해 weight를 미세 조정하는 추가적 학습을 시키는 방법도 가능하다.)</p>

<hr />

<p>###</p>

<hr />

:ET